{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sarcoma Use Case - Data Preparation\n",
    "\n",
    "### Algorithms\n",
    "* Summary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pkg_resources import importlib\n",
    "\n",
    "# from ohdsi import common\n",
    "from ohdsi.database_connector import connect\n",
    "from ohdsi import database_connector\n",
    "from ohdsi import common\n",
    "\n",
    "# import warnings\n",
    "# warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OMOP database\n",
    "### Get connection details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = connect(\n",
    "    dbms = \"postgresql\",\n",
    "    connection_string = \"jdbc:postgresql://localhost:5432/omopdb\",\n",
    "    user = \"ohdsi\",\n",
    "    password = \"ohdsi\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract the cohort data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions = importlib.import_module(\"v6-sessions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rps_cohort\n",
    "sql = \"SELECT person_id FROM omopcdm.measurement WHERE measurement_concept_id in (36770706)\"\n",
    "df = database_connector.query_sql(conn, sql)\n",
    "df = common.convert_from_r(df)\n",
    "print(df)\n",
    "pts_RPS = list(df.person_id.values)\n",
    "print(pts_RPS)\n",
    "\n",
    "rps_cohort_original = sessions.cohort.__create_cohort_dataframe(\n",
    "    connection=conn,\n",
    "    patient_ids=pts_RPS,\n",
    "    features=\"sarcoma\"\n",
    ")\n",
    "rps_cohort = rps_cohort_original.to_pandas()\n",
    "\n",
    "# pelvis_cohort\n",
    "sql = \"SELECT person_id FROM omopcdm.measurement WHERE measurement_concept_id in (36768752)\"\n",
    "df = database_connector.query_sql(conn, sql)\n",
    "df = common.convert_from_r(df)\n",
    "pts_Pelvis = list(df.person_id.values)\n",
    "\n",
    "pelvis_cohort_original = sessions.cohort.__create_cohort_dataframe(\n",
    "    connection=conn,\n",
    "    patient_ids=pts_Pelvis,\n",
    "    features=\"sarcoma\"\n",
    ")\n",
    "pelvis_cohort = pelvis_cohort_original.to_pandas()\n",
    "\n",
    "# rps_pelvis_cohort\n",
    "sql = \"SELECT person_id FROM omopcdm.measurement WHERE measurement_concept_id in (36770706, 36768752)\"\n",
    "df = database_connector.query_sql(conn, sql)\n",
    "df = common.convert_from_r(df)\n",
    "pts_RPS_Pelvis = list(df.person_id.values)\n",
    "\n",
    "rps_pelvis_cohort_original = sessions.cohort.__create_cohort_dataframe(\n",
    "    connection=conn,\n",
    "    patient_ids=pts_RPS_Pelvis,\n",
    "    features=\"sarcoma\"\n",
    ")\n",
    "rps_pelvis_cohort = rps_pelvis_cohort_original.to_pandas()\n",
    "\n",
    "\n",
    "print(f'RPS cohort: {len(rps_cohort)}')\n",
    "print(f'Pelvis cohort: {len(pelvis_cohort)}')\n",
    "print(f'RPS + Pelvis cohort: {len(rps_pelvis_cohort)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MockClient\n",
    "We mock to have two organizations with three databases each (<code>rps_cohort</code>, <code>pelvis_cohort</code> and <code>rps_pelvis_cohort</code>). <br><br>\n",
    "The first organization has:\n",
    "* <code>rps_cohort[:10]</code> (10 pts)\n",
    "* <code>pelvis_cohort[:10]</code> (10 pts)\n",
    "* <code>rps_pelvis_cohort[:10]</code> (10 pts)\n",
    "\n",
    "The second organization has:\n",
    "* <code>rps_cohort[10:]</code> (304 pts)\n",
    "* <code>pelvis_cohort[10:]</code> (276 pts)\n",
    "* <code>non_liposarcoma_cohort[10:]</code> (590 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vantage6.mock.network import MockNetwork\n",
    "\n",
    "network = MockNetwork(\n",
    "    \"v6-analytics\",\n",
    "    datasets=[\n",
    "        {\n",
    "            \"rps\": {\"database\": rps_cohort[:10], \"db_type\": \"omop\"},\n",
    "            \"pelvis\": {\"database\": pelvis_cohort[:10], \"db_type\": \"omop\"},\n",
    "            \"rps_pelvis\": {\"database\": rps_pelvis_cohort[:10], \"db_type\": \"omop\"}\n",
    "        },\n",
    "        {\n",
    "            \"rps\": {\"database\": rps_cohort[10:], \"db_type\": \"omop\"},\n",
    "            \"pelvis\": {\"database\": pelvis_cohort[10:], \"db_type\": \"omop\"},\n",
    "            \"rps_pelvis\": {\"database\": rps_pelvis_cohort[10:], \"db_type\": \"omop\"}\n",
    "        }\n",
    "    ],\n",
    "    collaboration_id=1,\n",
    ")\n",
    "\n",
    "client = network.user_client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "In the Data Preparation step we show summary statistics, there's different layouts for numeric vs categorical variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relevant variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_variables = [\n",
    "    \"age\", # num\n",
    "    \"tumor_size\", # num\n",
    "    \"histology\", # cat\n",
    "    \"sex\", # cat\n",
    "    \"fnclcc_grade\", # cat\n",
    "    \"multifocality\", # cat\n",
    "    \"completeness_of_resection\", # cat\n",
    "    \"tumor_rupture\", # cat\n",
    "    \"pre_operative_chemo\", # cat\n",
    "    \"post_operative_chemo\", # cat\n",
    "    \"pre_operative_radio\", # cat\n",
    "    \"post_operative_radio\", # cat\n",
    "    \"local_recurrence\", # cat\n",
    "    \"distant_metastasis\", # cat\n",
    "    \"status\", # cat\n",
    "    ]\n",
    "\n",
    "numeric_columns = [\"age\", \"tumor_size\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Send summary tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overall summary results\n",
    "task = client.task.create(\n",
    "    method=\"summary\",\n",
    "    organizations=[1],\n",
    "    arguments={\n",
    "        \"columns\": relevant_variables,\n",
    "        \"numeric_columns\": numeric_columns,\n",
    "        # \"organizations_to_include\": [0,1]\n",
    "    },\n",
    "    databases=[[{\"label\": \"rps\"}, {\"label\": \"pelvis\"}, {\"label\": \"rps_pelvis\"}]],\n",
    "    action=\"central_compute\"\n",
    ")\n",
    "\n",
    "client.wait_for_results(task_id=task.get(\"id\"))\n",
    "result = client.result.from_task(task_id=task.get(\"id\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # summary results per center\n",
    "task_centers = client.task.create(\n",
    "    method=\"summary_per_data_station\",\n",
    "    organizations=[1,2],\n",
    "    arguments={\n",
    "        \"columns\": relevant_variables,\n",
    "        \"numeric_columns\": numeric_columns,\n",
    "    },\n",
    "    name=\"Subtask summary\",\n",
    "    description=\"Compute summary per data station\",\n",
    "    databases=[[{\"label\": \"rps\"}, {\"label\": \"pelvis\"}, {\"label\": \"rps_pelvis\"}]],\n",
    "    action=\"federated_compute\"\n",
    ")\n",
    "\n",
    "client.wait_for_results(task_id=task_centers.get(\"id\"))\n",
    "result_centers = client.result.from_task(task_id=task_centers.get(\"id\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numeric variables\n",
    "<img src=\"../data%20preparation%20numeric.PNG\" alt=\"Data Preparation Numeric\" width=\"700\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bars(cohort, variable, organizations, measure):\n",
    "    medians = [round(result_center[cohort]['numeric'][variable][measure],2) for result_center in result_centers]\n",
    "    mapping = {'mock-1': 'INT', 'mock-2': 'ISS-FJD'}\n",
    "    center_names = [mapping[organizations.get(id)] for id in range(1, len(result_centers)+1)]\n",
    "    labels = [f\"{name} - {median}\" for name, median in zip(center_names, medians)]\n",
    "    print(center_names)\n",
    "    plt.figure(figsize=(4, 0.5 * len(medians)))\n",
    "\n",
    "    # Ensure background bars show up even if all medians are zero\n",
    "    max_value = max(max(medians), 1)\n",
    "\n",
    "    # Draw full-width light gray bars\n",
    "    plt.barh(center_names, [max_value] * len(medians), color='#e4e9ec', height=0.5)\n",
    "\n",
    "    # Overlay actual data bars\n",
    "    bars = plt.barh(center_names, medians, color=['#1ab5e5','#275b83'], height=0.5)\n",
    "\n",
    "    # Position labels consistently to the *left* of the bars, based on max_value\n",
    "    label_offset = max_value * 0.05  # adjust spacing as needed\n",
    "    label_x = -label_offset  # left of the bar start (which is at x=0)\n",
    "\n",
    "    for bar, label in zip(bars, labels):\n",
    "        plt.text(label_x, bar.get_y() + bar.get_height() / 2,\n",
    "                label, va='center', ha='right', fontsize=9)\n",
    "\n",
    "    plt.gca().set_axis_off()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort = 'rps'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort_names = list(result[0].keys())\n",
    "columns = cohort_names\n",
    "\n",
    "organizations = client.organization.list()\n",
    "organizations = {organization.get('id'): organization.get('name') for organization in organizations}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "organizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df = pd.DataFrame(columns=columns, index=['N', 'Mean', 'Min', 'Max', 'Missing'])\n",
    "df.index.name = 'Statistics'\n",
    "\n",
    "variables = result[0][cohort]['numeric'].keys()\n",
    "for variable in variables:\n",
    "\n",
    "    print(\"####################\")\n",
    "    print(variable)\n",
    "    print(\"####################\")\n",
    "\n",
    "    for cohort in cohort_names:\n",
    "        df.loc['N', cohort] = int(result[0][cohort]['numeric'][variable]['count'])\n",
    "        df.loc['Mean', cohort] = round(result[0][cohort]['numeric'][variable]['mean'], 1)\n",
    "        df.loc['Min', cohort] = int(result[0][cohort]['numeric'][variable]['min'])\n",
    "        df.loc['Max', cohort] = int(result[0][cohort]['numeric'][variable]['max'])\n",
    "        df.loc['Missing', cohort] = f\"{int(result[0][cohort]['numeric'][variable]['missing'])} ({round(result[0][cohort]['numeric'][variable]['missing']/result[0][cohort]['numeric'][variable]['count']*100, 1)})%\"\n",
    "\n",
    "    display(df)\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    for i, cohort in enumerate(cohort_names):\n",
    "        print(organizations)\n",
    "        print(\"\")\n",
    "        print(f\"Cohort {i+1}: {cohort}\")\n",
    "\n",
    "        print(\"\")\n",
    "        print(\"Q1 per center\")\n",
    "        # for id, result_center in enumerate(result_centers):\n",
    "        #     print(f\"{organizations.get(id)}: {result_center[cohort]['numeric'][variable]['median']}\")\n",
    "        plot_bars(cohort, variable, organizations, 'q_25')\n",
    "\n",
    "        print(\"\")\n",
    "        print(\"Median per center\")\n",
    "        # for id, result_center in enumerate(result_centers):\n",
    "        #     print(f\"{organizations.get(id)}: {result_center[cohort]['numeric'][variable]['median']}\")\n",
    "        plot_bars(cohort, variable, organizations, 'median')\n",
    "\n",
    "        print(\"\")\n",
    "        print(\"Q3 per center\")\n",
    "        # for id, result_center in enumerate(result_centers):\n",
    "        #     print(f\"{organizations.get(id)}: {result_center[cohort]['numeric'][variable]['median']}\")\n",
    "        plot_bars(cohort, variable, organizations, 'q_75')\n",
    "\n",
    "        print(\"Missing per center\")\n",
    "        # for id, result_center in enumerate(result_centers):\n",
    "        #     print(f\"{organizations.get(id)}: {result_center[cohort]['numeric'][variable]['missing']}\")\n",
    "        # print(\"\")\n",
    "        plot_bars(cohort, variable, organizations, 'missing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical variables\n",
    "<img src=\"../data%20preparation%20categorical.PNG\" alt=\"Data Preparation Categorical\" width=\"700\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_full_row_border(styler, row_label, border=\"3px solid black\"):\n",
    "    \"\"\"\n",
    "    Add a horizontal border across the entire table (index + data columns)\n",
    "    for the given row label in a pandas Styler.\n",
    "    \"\"\"\n",
    "    df = styler.data\n",
    "    row_pos = df.index.get_loc(row_label) + 1  # +1 because nth-child counts from 1\n",
    "\n",
    "    # Apply styling to all cells in that HTML row\n",
    "    return styler.set_table_styles(\n",
    "        [\n",
    "            {\n",
    "                \"selector\": f\"tbody tr:nth-child({row_pos})\",\n",
    "                \"props\": [( \"border-top\", border )]\n",
    "            }\n",
    "        ],\n",
    "        overwrite=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categories vs Total table (FREQ)\n",
    "cohort_names = list(result[0].keys())\n",
    "\n",
    "organizations = client.organization.list()\n",
    "organizations = {organization.get('id'): organization.get('name') for organization in organizations}\n",
    "\n",
    "variables = result[0][cohort]['categorical'].keys()\n",
    "for variable in variables:\n",
    "\n",
    "    print(\"####################\")\n",
    "    print(variable)\n",
    "    print(\"####################\")\n",
    "\n",
    "    columns = cohort_names\n",
    "    categories = list(result[0][cohort]['counts_unique_values'][variable].keys())\n",
    "    categories_cap = [category.capitalize() for category in categories if category != 'N/A']\n",
    "    indices = sorted(categories_cap) + ['Total', 'Missing']\n",
    "    df = pd.DataFrame(columns=columns, index=indices)\n",
    "    df.index.name = variable\n",
    "\n",
    "    for cohort in cohort_names:\n",
    "        for category in categories:\n",
    "\n",
    "            if category=='N/A':\n",
    "                df.loc['Missing', cohort] = int(result[0][cohort]['counts_unique_values'][variable][category])\n",
    "            else:\n",
    "                df.loc[category.capitalize(), cohort] = int(result[0][cohort]['counts_unique_values'][variable][category])\n",
    "                df.loc['Missing', cohort] = int(0)\n",
    "\n",
    "            # df.loc[category.capitalize(), cohort] = int(result[0][cohort]['counts_unique_values'][variable][category])\n",
    "\n",
    "        df.loc['Total', cohort] = int(df.loc[categories_cap, cohort].sum())\n",
    "        df.loc['Missing', cohort] = f\"{df.loc['Missing', cohort]} ({round(df.loc['Missing', cohort]/(df.loc['Missing', cohort]+df.loc['Total', cohort])*100, 1)})%\"\n",
    "\n",
    "    desired_order = [\"rps\", \"pelvis\", \"rps_pelvis\"]\n",
    "    df = df[desired_order]\n",
    "    df = add_full_row_border(df.style, \"Total\", \"1px solid black\")\n",
    "\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Category vs Cohorts: Radio button view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort_names = list(result[0].keys())\n",
    "\n",
    "organizations = client.organization.list()\n",
    "organizations = {organization.get('id'): organization.get('name') for organization in organizations}\n",
    "\n",
    "variables = result[0][cohort]['categorical'].keys()\n",
    "for variable in variables:\n",
    "\n",
    "    print(\"####################\")\n",
    "    print(variable)\n",
    "    print(\"####################\")\n",
    "\n",
    "    columns = cohort_names\n",
    "    categories = list(result[0][cohort]['counts_unique_values'][variable].keys())\n",
    "    categories_cap = [category.capitalize() for category in categories if category != 'N/A']\n",
    "    indices = sorted(categories_cap) + ['Total', 'Missing']\n",
    "    df = pd.DataFrame(columns=columns, index=indices)\n",
    "    df.index.name = variable\n",
    "\n",
    "    for cohort in cohort_names:\n",
    "        for category in categories:\n",
    "\n",
    "            if category=='N/A':\n",
    "                df.loc['Missing', cohort] = int(result[0][cohort]['counts_unique_values'][variable][category])\n",
    "            else:\n",
    "                df.loc[category.capitalize(), cohort] = int(result[0][cohort]['counts_unique_values'][variable][category])\n",
    "                df.loc['Missing', cohort] = int(0)\n",
    "\n",
    "            # df.loc[category.capitalize(), cohort] = int(result[0][cohort]['counts_unique_values'][variable][category])\n",
    "\n",
    "        df.loc['Total', cohort] = int(df.loc[categories_cap, cohort].sum())\n",
    "        # df.loc['Missing', cohort] = f\"{df.loc['Missing', cohort]} ({round(df.loc['Missing', cohort]/(df.loc['Missing', cohort]+df.loc['Total', cohort])*100, 1)})%\"\n",
    "\n",
    "    # -------- 1. Frequencies --------\n",
    "    print(\"\\nFrequencies\")\n",
    "    display(add_full_row_border(df.style, \"Total\", \"1px solid black\"))\n",
    "\n",
    "    # -------- 2. Percentages (overall %) --------\n",
    "    df_pct = df.copy().astype(float)\n",
    "    grand_total = df_pct.loc['Total'].sum()+df_pct.loc['Missing'].sum()\n",
    "    df_percent = (df_pct / grand_total * 100).round(1).astype(str) + \"%\"\n",
    "    print(\"\\nPercentages of total\")\n",
    "    display(add_full_row_border(df_percent.style, \"Total\", \"1px solid black\"))\n",
    "\n",
    "    # -------- 3. Row percentages --------\n",
    "    df_row = df.copy().astype(float)\n",
    "    for idx in df_row.index:\n",
    "        row_total = df_row.loc[idx].sum()\n",
    "        if row_total > 0:\n",
    "            df_row.loc[idx] = df_row.loc[idx] / row_total * 100\n",
    "    df_row_pct = df_row.round(1).astype(str) + \"%\"\n",
    "\n",
    "    print(\"\\nRow percentages\")\n",
    "    display(add_full_row_border(df_row_pct.style, \"Total\", \"1px solid black\"))\n",
    "\n",
    "    # # -------- 4. Column percentages --------\n",
    "    df_col = df.copy().astype(float)\n",
    "    df_col = df_col.drop(index='Total')\n",
    "    df_col['Total'] = df_col.sum(axis=1)\n",
    "\n",
    "    for col in df_col.columns:\n",
    "        col_total = df_col.loc[categories_cap+[\"Missing\"], col].sum()\n",
    "        if col_total > 0:\n",
    "            df_col[col] = df_col[col] / col_total * 100\n",
    "    df_col_pct = df_col.round(1).astype(str) + \"%\"\n",
    "\n",
    "    # print(\"\\nColumn percentages\")\n",
    "    # display(add_full_row_border(df_col_pct.style, \"Missing\", \"1px solid black\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Category vs Centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cohort_names = list(result[0].keys())\n",
    "cohort_names = ['rps', 'pelvis', 'rps_pelvis']\n",
    "\n",
    "organizations = client.organization.list()\n",
    "organizations = {organization.get('id'): organization.get('name') for organization in organizations}\n",
    "\n",
    "variables = result[0][cohort]['categorical'].keys()\n",
    "for variable in variables:\n",
    "    print(\"####################\")\n",
    "    print(variable)\n",
    "    print(\"####################\")\n",
    "\n",
    "    columns = ['Total'] + cohort_names\n",
    "    categories = list(result[0][cohort]['counts_unique_values'][variable].keys())\n",
    "    categories_cap = [category.capitalize() for category in categories if category != 'N/A']\n",
    "    indices = sorted(categories_cap) + ['Total', 'Missing']\n",
    "    df = pd.DataFrame(columns=columns, index=indices)\n",
    "    df.index.name = variable\n",
    "\n",
    "    for i, cohort in enumerate(cohort_names):\n",
    "        print(f\"Cohort {i+1}: {cohort}\")\n",
    "\n",
    "        columns = ['Total'] + list(organizations.values())\n",
    "        df_centers = pd.DataFrame(columns=columns, index=indices)\n",
    "        df_centers.index.name = variable\n",
    "\n",
    "        for id, result_center in enumerate(result_centers,1):\n",
    "\n",
    "            categories = list(result_center[cohort]['counts_unique_values'][variable].keys())\n",
    "\n",
    "            for category in categories:\n",
    "                if category=='N/A':\n",
    "                    df_centers.loc['Missing', organizations.get(id)] = int(result_center[cohort]['counts_unique_values'][variable][category])\n",
    "                else:\n",
    "                    df_centers.loc[category.capitalize(), organizations.get(id)] = int(result_center[cohort]['counts_unique_values'][variable][category])\n",
    "                    df_centers.loc['Missing', organizations.get(id)] = int(0)\n",
    "                df_centers = df_centers.fillna(0)\n",
    "                # df_centers.loc[category.capitalize(), organizations.get(id)] = int(result_center[cohort]['counts_unique_values'][variable][category])\n",
    "\n",
    "            df_centers.loc['Total', organizations.get(id)] = int(df_centers.loc[categories_cap, organizations.get(id)].sum())\n",
    "            # df_centers.loc['Missing', organizations.get(id)] = f\"{int(result_center[cohort]['categorical'][variable]['missing'])} ({round(result_center[cohort]['categorical'][variable]['missing']/result_center[cohort]['categorical'][variable]['count']*100, 1)})%\"\n",
    "\n",
    "\n",
    "        indices_no_total_missing = [idx for idx in df_centers.index if idx not in ['Total', 'Missing']]\n",
    "        for category in indices_no_total_missing:\n",
    "            if category!='N/A':\n",
    "                df_centers.loc[category.capitalize(), 'Total'] = int(df_centers.loc[category.capitalize(), list(organizations.values())].sum())\n",
    "                df_centers.loc['Total', 'Total'] = int(df_centers.loc['Total', list(organizations.values())].sum())\n",
    "                # df_centers.loc['Missing', 'Total'] = f\"{int(df_centers.loc['Missing'][list(organizations.values())].str.split(' ').str[0].astype(int).sum())} ({round(df_centers.loc['Missing'][list(organizations.values())].str.split(' ').str[0].astype(int).sum()/df_centers.loc['Total', 'Total']*100, 1)})%\"\n",
    "                # df_centers.loc['Missing', 'Total'] = f\"{int(df_centers.loc['Missing'][list(organizations.values())].astype(int).sum())} ({round(df_centers.loc['Missing'][list(organizations.values())].astype(int).sum()/df_centers.loc['Total', 'Total']*100, 1)})%\"\n",
    "                df_centers.loc['Missing', 'Total'] = int(df_centers.loc['Missing'][list(organizations.values())].astype(int).sum())\n",
    "\n",
    "        mapping = {'mock-1': 'INT', 'mock-2': 'ISS-FJD'}\n",
    "        df_centers.rename(columns=mapping, inplace=True)\n",
    "        display(add_full_row_border(df_centers.style, \"Total\", \"1px solid black\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Category vs Centers: Radio button view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO (optional): Make radio button version of category vs centers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
